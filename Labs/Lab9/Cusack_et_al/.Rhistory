samp60 = sample(x4,60,replace=F)
samp60
samp60ave = mean(samp60)
samp60ave
x4distr=c()
for(i in 1:1200){samp = sample(x4,60,replace=F); x4disr = c(x4distr,mean(samp))}
x4distrterm = x4distr[133]
x4distr
x4distr2 = c()
for(i in 1:20000){samp = sample(x4,120,replace=F); x4distr2 = c(x4distr2,mean(samp))}
hist(x4distr2)
x4distr2ave = mean(x4distr2)
x4distr2ave
x4distr2sd = sd(x4distr2)
x4distr2sd
x4lower = x4distr2 + qnorm(0.025) * x4sd / sqrt(120)
x4upper = x4distr2 + qnorm(0.975) * x4sd / sqrt(120)
x5a = pnorm(1,mean=1.10,sd=0.085,lower.tail=F)
x5a
x5b = qnorm(.88,mean=995,sd=175)
x5b
x5c = dbinom(92,size=153,prob=.5)
x5c
x5d = pbinom(9,size=30,prob=.20)
x5d
n = 50
while(1-pbinom(49,n,.10)<.90){n=n+1}
n
x5e = n
ls()
save.image("~/R/School/Statistics/McSpadden_Project2.RData")
R.version
# This portion of the code makes sure you have all the neccesary packages. Follow the promts in the console.
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.11")
pckgs_bio <- c("msa", "Biostrings")
pckgs <- c("phangorn", "ape")
miss_bio <- pckgs_bio[!pckgs_bio %in% installed.packages()]
miss <- pckgs[!pckgs %in% installed.packages()]
#install missing packages
if( length(miss_bio)) BiocManager::install(miss_bio)
install.packages("ggmsa", dependencies=TRUE)
#Call the packages
library(msa)
library(Biostrings)
library(phangorn)
library(ape)
library(ggmsa)
install.packages("phangorn")
library(phangorn)
library(phangorn)
updateR()
install.packages("installr")
library(installr)
updateR()
versionR()
clc
R.version.string
chips <- 5
guests <- 8
#lab step #5 - how many bags each guest will eat
avgConsumption <- 0.4
chipsRemaining <- 5 - ((guests + 1) * avgConsumption)
# Penny's rank for episode IV
PennyIV <- penny[4]
# Penny's ranking of each star wars episode
penny <- c(5,9,8,3,1,2,4,7,6)
# Lenny's ranking of each star wars episode
lenny <- c(6,5,4,9,8,7,3,2,1)
# Stewie's ranking of each star wars episode
stewie <- c(1,9,5,6,8,7,2,3,4)
# Penny's rank for episode IV
PennyIV <- penny[4]
# Lenny's rank for episode IV
LennyIV <- lenny[4]
# everyones rankings
everyone <- cbind(penny,lenny, stewie)
View(everyone)
View(everyone)
# everyones rankings
everyone <- cbind(self,penny,lenny, stewie)
,
# self ranking of each star wars episode
self <- c(7,9,8,1,2,3,4,6,5)
# everyones rankings
everyone <- cbind(self,penny,lenny, stewie)
str(PennyIV, penny, everyone)
# putting ranking vectors into a dataframe
everyoneDF <- data.frame(everyone)
View(everyoneDF)
View(everyoneDF)
everyoneDF2 <- data.frame(everyone)
View(everyoneDF2)
View(everyoneDF2)
View(everyoneDF)
View(everyone)
View(everyone)
dim(eveyone,everyoneDF1)
dim(everyone,everyoneDF1)
# putting ranking vectors into a dataframe in two ways
everyoneDF1 <- data.frame(everyone)
dim(everyone,everyoneDF1)
dim(everyone)
dim(everyoneDF1)
str(everyone)
str(everyoneDF1)
typeof(everyone)
typeof(everyoneDF1)
episodeNames <- c("I","II","III","IV","V","VI","VII","VII","IX")
help("row.names")
#name rows of ranking vector
row.names(everyone) <- episodeNames
View(everyone)
View(everyone)
#name rows of ranking DF
row.names(everyoneDF1) <- episodeNames
View(everyoneDF1)
View(everyoneDF1)
#name rows of ranking vector
row.names(everyone) <- episodeNames
#name rows of ranking vector
row.names(everyone) <- episodeNames
#name rows of ranking DF
row.names(everyoneDF1) <- episodeNames
# Vector of episode names
episodeNames <- c("I","II","III","IV","V","VI","VII","VIII","IX")
#name rows of ranking vector
row.names(everyone) <- episodeNames
#name rows of ranking DF
row.names(everyoneDF1) <- episodeNames
View(everyoneDF)
View(everyoneDF)
View(everyoneDF1)
View(everyoneDF1)
everyone[3:,]
everyone[3:,:]
everyone[3,]
everyoneDF1[,4]
self[5]
#penny's rank of episode 2
penny[2]
#everyones rank for episodes 4-6
everyone[4:6,]
# everyones rank for 2,5,7
everyone[c(2,5,7),]
# penny and Stewie ranking for 4 and 6
everyone[c(4,6),c(2,4)]
everyone
lennyII <- everyone[2,3]
everyone[2,3] == everyone[5,3]
everyone[2,3] = everyone[5,3]
everyone
everyone[5,3] = lennyII
everyone
everyone["III","Penny"]
everyone["III","penny"]
everyoneDF1["I",'self']
# switch back lenny's ranks for 2 and 5 using names
lennyII <- everyone["II","lenny"]
everyone["II","lenny"] = everyone["VI","lenny"]
everyone["VI","lenny"] = lennyII
# re-do Lenny's switch with DF
lennyIIDF <- everyoneDF1$lenny[2]
everyoneDF1$lenny[2] = everyoneDF1$lenny[5]
everyoneDF1$lenny[5]= lennyIIDF
print(hi)
for (i in 1:5){
print("hi")
}
for (i in 1:5){
print("hi")
}
it <- 1:5
print(i)
for (i in 1:5){
print(i)
}
for (i in 1:5){
print(i)
}
piggyBank <- 10 #dollars
allowance <- 5 #dollars
gumCost <- 2 * 1.34 #cost of 2 packs of gum
weeks <- 8 #relevant time frame
for (i in 1:weeks) {
piggyBank <- piggyBank + allowance - gumCost
}
# Problem 1
for (i in 1:10){
print("hi")
}
# problem 2
piggyBank <- 10 #dollars
allowance <- 5 #dollars
gumCost <- 2 * 1.34 #cost of 2 packs of gum
weeks <- 8 #relevant time frame
for (i in 1:weeks) {
piggyBank <- piggyBank + allowance - gumCost
print(piggyBank)
}
for (i in 1:7){
pop <- pop - (pop * rate)
print(pop)
}
#Problem 3
pop <- 2000 # current population size
rate <- 0.05 # decay rate
for (i in 1:7){
pop <- pop - (pop * rate)
print(pop)
}
#problem 4
n[1] = 2500
#problem 4
n <- 1:12
n[1] = 2500
#problem 4
n <- rep(NA, 12)
n[1] = 2500
#problem 4
n <- rep(NA, 12) # pre allocated vector for abundance of pop
n[1] = 2500 # abundance of population at time 1
K <- 10000 # carrying cap
r <- 0.8 # growth rate
t <- 1:12 relevant time frame
for (i in t){
n[t] <- n[t-1] + ( r * n[t-1] * (K - n[t-1])/K )
}
for (i in t){
n[i] <- n[i-1] + ( r * n[i-1] * (K - n[i-1])/K )
}
t <- 1:12 relevant time frame
t <- 1:12 #relevant time frame
for (i in t){
n[i] <- n[i-1] + ( r * n[i-1] * (K - n[i-1])/K )
}
for (i in 2:13){
n[i] <- n[i-1] + ( r * n[i-1] * (K - n[i-1])/K )
}
for (i in 2:13){
n[i] <- n[i-1] + ( r * n[i-1] * (K - n[i-1])/K )
print(n[i])
}
# Problem 5a
vec <- rep(0,18)
print(vec)
#problem 5b
for (i in seq(1,18)){
vec[i] <- i * 3
}
print(vec)
#problem 5c
vec1 <- rep(0,18) # vector with 18 zeros
vec1[1] <- 1
for (i in 1:18){
vec1[i + 1] <- 1 + (2 * i)
}
print(vec1)
for (i in 1:18){
vec1[i + 1] <- 1 + (2 * vec1[i])
}
print(vec1)
for (i in 1:17){
vec1[i + 1] <- 1 + (2 * vec1[i])
}
print(vec1)
for (i in 1:17){
vec1[i + 1] <- 1 + (2 * vec1[i])
}
print(vec1)
#problem 5c
vec1 <- rep(0,18) # vector with 18 zeros
vec1[1] <- 1
for (i in 1:17){
vec1[i + 1] <- 1 + (2 * vec1[i])
}
print(vec1)
# problem 6
fib <- rep(0,20)
fib[2] <- 1
# for loop for fibonacci sequence
for (i in 3:22){
fib[i] <- fib[i-2] + fib[i-1]
}
print(fib)
# for loop for fibonacci sequence
for (i in 3:20){
fib[i] <- fib[i-2] + fib[i-1]
}
# problem 6
fib <- rep(0,20) #pre-allocation for fibonacci
fib[2] <- 1
# for loop for fibonacci sequence
for (i in 3:20){
fib[i] <- fib[i-2] + fib[i-1]
}
print(fib)
time <- 1:12 #relevant time frame
for (i in 2:13){
n[i] <- n[i-1] + ( r * n[i-1] * (K - n[i-1])/K ) # logistic growth eqn
abundance <- n
print(n[i])
}
plot(time,abundance)
#problem 4 and problem 7
n <- rep(NA, 12) # pre allocated vector for abundance of pop
n[1] = 2500 # abundance of population at time 1
K <- 10000 # carrying cap
r <- 0.8 # growth rate
time <- 1:12 #relevant time frame
for (i in 2:12){
n[i] <- n[i-1] + ( r * n[i-1] * (K - n[i-1])/K ) # logistic growth eqn
abundance <- n
print(n[i])
}
plot(time,abundance)
#This function converts three column data into an adjacency matrix
convertThreeCol <- function(ThreeColumnData){
uniqueNames <- unique(c(ThreeColumnData$Person1[],ThreeColumnData$Person2[])) # extract unique names from dataframe into a vector
newMat <- matrix(NA, nrow = length(uniqueNames), ncol = length(uniqueNames)) #pre-allocate new matrix with NAs
# set row and col names to unique names
colnames(newMat) <- uniqueNames
rownames(newMat) <- uniqueNames
#fill in new matrix with corresponding data
for (row in 1:nrow(ThreeColumnData)){
#extract two names and corresponding interaction strength
p1 <- ThreeColumnData$Person1[row]
p2 <- ThreeColumnData$Person2[row]
interactionStrength <- ThreeColumnData$InteractionStrength[row]
#store corresponding interaction strengths
newMat[p1, p2] <- interactionStrength
newMat[p2, p1] <- interactionStrength
}
return(newMat)
}
# Read in the data
ThreeColumnData <- read.csv(file = "16_Week6_Problem_Data.csv",
stringsAsFactors = F,
header = T)
setwd("~/School/SP21/Computational_Bio_4420/LabsAndHW/InClassProblems")
# Read in the data
ThreeColumnData <- read.csv(file = "16_Week6_Problem_Data.csv",
stringsAsFactors = F,
header = T)
convertThreeCol(ThreeColumnData)
setwd("~/School/SP21/Computational_Bio_4420/LabsAndHW/Labs/Lab9/Cusack_et_al")
####################################################
## STEP 1:  Import and clean data:
####################################################
rm(list = ls()) # start with clean workspace
camData <- read.csv("~/compbio/CompBio_on_git/Datasets/Cusack_et_al/Cusack_et_al_random_versus_trail_camera_trap_data_Ruaha_2013_14.csv",
stringsAsFactors = F)
camData <- read.csv("Cusack_et_al_random_versus_trail_camera_trap_data_Ruaha_2013_14.csv",
stringsAsFactors = F)
require("lubridate")
datesTimes2 <- parse_date_time( x = camData$DateTime,
orders = c("dmy HM", "dmY HM"),
tz = "Africa/Kampala")
camData$DateTime <- datesTimes2
summary(camData$DateTime)
# Here are some exercises that were demonstrated in the precorded lecture
require("dplyr")
speciesCountsByStation <- summarise( group_by(camData, Species, Placement, Station),
Freq = n(),
.groups = "drop")
require("tidyr")
scbsWide <- pivot_wider( speciesCountsByStation,
values_from = Freq,
names_from = Placement,
values_fill = 0 )
# Breakout Room 1
speciesCountBySeason <- summarize( group_by(camData, Species, Station, Season),
TotalCount = n(),
.groups = "drop" )
# Breakout Room 2
# use data frame from group 1 to create summary statistics by species and season:
SeasonMeanStd <- summarise( group_by(speciesCountBySeason, Species, Season),
meanCount = mean(TotalCount),
sdCount = sd(TotalCount) ,
.groups = "drop" )
# Breakout Room 3
# pivot the data frame from Breakout Room 1 to be wider:
NewSeasonTable <-  pivot_wider(speciesCountBySeason,
values_from = TotalCount,
names_from = Season,     # what new columns we want
values_fill = 0)         # converts NAs to zeros
# Breakout Room 4
# do the reverse the operation of Breakout Room 3:
outdf <- pivot_longer(NewSeasonTable,
cols = c("D", "W"),
names_to = "Season",
values_to = "TotalCount")
# Compare output of last operation with Breakout Room 1's data frame:
head(speciesCountBySeason)
head(outdf)
summary(speciesCountBySeason)
summary(outdf)
# Base R method for Breakout Room 1 task:
oldSchoolCrossTab <- as.data.frame(
with( camData,
table( Species, Station, Season )))
head(oldSchoolCrossTab)
# How big is it?
nrow(oldSchoolCrossTab)
# 4428 rows; note that 4428 is equal to
# numSpecies * numStations * numSeasons
# Let's compare to check
nrow(oldSchoolCrossTab) - sum(oldSchoolCrossTab$Freq == 0) == nrow(speciesCountBySeason)
# It's TRUE!  That means the absence/presence of zeros likely accounts for the difference
# Let's really check for sure:
noZerosOld <- subset( oldSchoolCrossTab, Freq != 0 )
# To directly compare, we have to make sure they are ordered/sorted the same exact way
sortedOldNoZeros <- arrange( .data = noZerosOld, Species, Station, Season )
sortedNewOne <- arrange( .data = speciesCountBySeason, Species, Station, Season )
all( sortedOldNoZeros == sortedNewOne ) # It all checks out!  Woohoo!
# First we would need to know how unique entries for each
# factor we are wanting to consider:
uSeasons <- unique(camData$Season)
uStations <- unique(camData$Station)
uSpecies <- unique(camData$Species)
# now let's pre allocate a data frame for the cross-tabulation:
totalRows <- length(uSeasons) * length(uStations) * length(uSpecies)
totalRows == nrow(oldSchoolCrossTab) # check; should be true
countsBySeason <- data.frame( Species = rep("", totalRows), # chr
Station = rep("", totalRows), # chr
Season = rep("", totalRows),  # chr
TotalCount = rep(0, totalRows), # numeric
stringsAsFactors = F)
# here's one way to do a three-way cross-tabulation.
# this should produce the same cross-tab as the "oldSchool" method above:
rowCount <- 1 # row index counter
system.time({   # time it just for fun
for ( i in 1:length(uSpecies) ) {
focalSpecies <- uSpecies[i]  # species one at a time
# make a smaller data frame for the subsequent (inner) loops, to speed up performance
subDF1 <- subset( camData, Species == focalSpecies )
for ( j in 1:length(uStations) ) {
focalStation <- uStations[j] # stations one at a time
subDF2 <- subset( subDF1, Station == focalStation )
for ( k in 1:length(uSeasons) ) {
focalSeason <- uSeasons[k] # seasons one at a time
# fill in first three columns:
countsBySeason[rowCount, 1:3] <- c(focalSpecies, focalStation, focalSeason)
if (nrow(subDF2) > 0 ) {
# use logical tests to find number of matching entries in the data set:
nMatches <- sum( subDF2$Season == focalSeason )
} else {
nMatches <- 0
}
countsBySeason$TotalCount[rowCount] <- nMatches # store result
rowCount <- rowCount + 1 # increment row counter
}
}
}
})
head(countsBySeason)
# let's now check that did the same thing
sortedLoopCounts <- arrange( countsBySeason, Species, Station, Season )
sortedOldSchool <- arrange( oldSchoolCrossTab, Species, Station, Season )
all( sortedLoopCounts == sortedOldSchool )
system.time({
oldSchoolCrossTab <- as.data.frame(
with( camData,
table( Species, Station, Season )))
})
system.time({
# Breakout Room 1
speciesCountBySeason <- summarise( group_by(camData, Species, Station, Season),
TotalCount = n(),
.groups = "drop" )
})
# for this operation, the method with table() is faster than summarise();
# for this operation, the method with table() is faster than summarise();
# summarise() is a more flexible function, however, capable of much in
wideImpala <- subset(NewSeasonTable, Species =- "Impala")
ggplot(data = wideImpala, aes(x = Species, y = D - W)) + geom_boxplot()
require(“ggplot2”)
require(ggplot2)
ggplot(data = wideImpala, aes(x = Species, y = D - W)) + geom_boxplot()
ggplot(data = wideImpala, aes(y = D - W)) + geom_boxplot()
xlab("Impala")
ylab('Dry Minus Wet')
ggplot(data = wideImpala, aes(y = D - W)) + geom_boxplot()
plot <- ggplot(data = wideImpala, aes(y = D - W)) + geom_boxplot()
xlab("Impala")
ylab('Dry Minus Wet')
plot + labs(x = "New x label")
plot + labs(x = "Impala")
plot + labs(x = "Impala", y = Dry minus Wet)
plot + labs(x = "Impala", y = "Dry minus Wet")
plot + labs(x = "Impala", y = "Dry minus Wet Season Count by Station")
plot + labs(title = "Impala Observations from 53 Stations" x = "Impala", y = "Dry minus Wet Season Count by Station")
plot + labs(title = "Impala Observations from 53 Stations", x = "Impala", y = "Dry minus Wet Season Count by Station")
plot <- ggplot(data = wideImpala, aes(y = D - W)) + geom_boxplot() + labs(title = "Impala Observations from 53 Stations", x = "Impala", y = "Dry minus Wet Season Count by Station")
plot <- ggplot(data = wideImpala, aes(y = D - W)) + geom_boxplot() + labs(title = "Impala Observations from 53 Stations", x = "Impala", y = "Dry minus Wet Season Count by Station")
plot
longImpala <- subset(speciesCountBySeason, Species == "Impala")
ggplot( longImpala, aes( x = Season, y = TotalCount )) + geom_boxplot() + labs( y = “Total Counts of Impala at 53 Stations”)
ggplot(longImpala, aes( x = Season, y = TotalCount )) + geom_boxplot() + labs(y = "Total Counts of Impala at 53 Stations")
install.packages("ggplot2")
library("ggplot2")
require("dplyr")
speciesCountsByStation <- summarise( group_by(camData, Placement, Station),
Freq = n(),
.groups = "drop")
require("tidyr")
scbsWide <- pivot_wider( speciesCountsByStation,
values_from = Freq,
names_from = Placement,
values_fill = 0 )
ggplot(data = scbsWide, aes(x = Random, y = Trail)) + geom_point() +geom_smooth (method = lm)
